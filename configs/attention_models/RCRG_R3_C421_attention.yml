# RCRG_R3_C421_attention.yml

model:        
  num_classes: 
    person_activity: 9
    group_activity: 8

  num_clases_label:
    group_activity: ["r_set", "r_spike" , "r-pass", "r_winpoint", "l_winpoint", "l-pass", "l-spike", "l_set"]

training:    
  group_activity:
    batch_size: 4
    learning_rate: 0.00005 # 5e-5
    epochs: 45
    optimizer: "AdamW"
    # momentum: 0.9
    weight_decay: 1
    label_smoothing: 0.01
    balance: False
    
data:
  dataset_name: "GroupActivityDataset"
  data_dir: "data"
  annot_path: "data/annot_all.pkl"
  videos_path: "data/videos"

  video_splits:
    train: [1, 3, 6, 7, 10, 13, 15, 16, 18, 22, 23, 31, 32, 36, 38, 39, 40, 41, 42, 48, 50, 52, 53, 54]
    validation: [0, 2, 8, 12, 17, 19, 24, 26, 27, 28, 30, 33, 46, 49, 51]
    test: [4, 5, 9, 11, 14, 20, 21, 25, 29, 34, 35, 37, 43, 44, 45, 47]

experiment:
  name: "RCRG_R3_C421_temporal"
  version: 1
  seed: 31
  description: "There relational layers (of sizes 512, 256 and 128) 
with clique sizes of the layers set to (4, 2, 1).
The first layer has 4 cliques, with each team divided into 2 cliques.
but this time using graph attentional operator instead of MLP."
