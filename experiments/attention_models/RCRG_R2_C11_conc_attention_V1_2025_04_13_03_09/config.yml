!!python/object:utils.helper_utils.helper.Config
data:
  annot_path: input/group-activity-recognition-volleyball/annot_all.pkl
  data_dir: /kaggle/input/group-activity-recognition-volleyball/annot_all.pkl
  dataset_name: GroupActivityDataset
  video_splits:
    test:
    - 4
    - 5
    - 9
    - 11
    - 14
    - 20
    - 21
    - 25
    - 29
    - 34
    - 35
    - 37
    - 43
    - 44
    - 45
    - 47
    train:
    - 1
    - 3
    - 6
    - 7
    - 10
    - 13
    - 15
    - 16
    - 18
    - 22
    - 23
    - 31
    - 32
    - 36
    - 38
    - 39
    - 40
    - 41
    - 42
    - 48
    - 50
    - 52
    - 53
    - 54
    validation:
    - 0
    - 2
    - 8
    - 12
    - 17
    - 19
    - 24
    - 26
    - 27
    - 28
    - 30
    - 33
    - 46
    - 49
    - 51
  videos_path: input/group-activity-recognition-volleyball/videos
experiment:
  description: Close to the RCRG-1R-1C variant, but uses 2 relational layers (2R)
    of sizes 256 and 128. The graphs of these 2 layers are 1 clique (11C) of all people.
    -conc postfix is used to indicate concatenation pooling instead of max-pooling.
    but this time using graph attentional operator instead of MLP.
  name: RCRG_R2_C11_conc_attention
  seed: 31
  version: 1
model:
  num_clases_label:
    group_activity:
    - r_set
    - r_spike
    - r-pass
    - r_winpoint
    - l_winpoint
    - l-pass
    - l-spike
    - l_set
  num_classes:
    group_activity: 8
    person_activity: 9
training:
  group_activity:
    batch_size: 4
    epochs: 50
    label_smoothing: 0.15
    learning_rate: 1.0e-05
    optimizer: AdamW
    weight_decay: 1
